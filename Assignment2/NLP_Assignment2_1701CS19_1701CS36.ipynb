{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Assignment2_1701CS19_1701CS36.ipynb","provenance":[{"file_id":"1P9q6s10qEg6ZVmAhvgu3GdQeOJ0eM16N","timestamp":1613930596206}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQBTmQHPrv1y","executionInfo":{"status":"ok","timestamp":1613945879667,"user_tz":-330,"elapsed":10572,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"bcc2d32a-30b0-4f8c-8345-7f0b161c565a"},"source":["import pandas as pd\r\n","import numpy as np\r\n","from sklearn.model_selection import train_test_split, KFold\r\n","from sklearn.model_selection import StratifiedKFold\r\n","\r\n","import seaborn as sns\r\n","\r\n","from gensim.models import KeyedVectors\r\n","\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.utils.np_utils import to_categorical\r\n","from keras.models import Sequential\r\n","from keras.layers import Embedding\r\n","from keras.layers import Dense, Input\r\n","from keras.layers import TimeDistributed\r\n","from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\r\n","from keras.models import Model\r\n","from keras.preprocessing.text import Tokenizer\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","from sklearn.utils import shuffle\r\n","!pip install seqeval\r\n","import seqeval\r\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=156d9d3bcf70ce3abc864274a57a7b00aa4114d0c6b21d240b2d8842400432be\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1EeMsVLryvU","executionInfo":{"status":"ok","timestamp":1613946006376,"user_tz":-330,"elapsed":137198,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"457d1496-13e5-4cf3-d30b-de7bb6660931"},"source":["!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\r\n","!pip install gensim\r\n","\r\n","from gensim.models import KeyedVectors\r\n","EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\r\n","word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\r\n","\r\n","# https://drive.google.com/drive/folders/1NYeUaJkhv5LpvUafTgYtZBErMyTka8aq?usp=sh\r\n","# Download link for datasets"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-02-21 22:17:58--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.12.94\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.12.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1647046227 (1.5G) [application/x-gzip]\n","Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n","\n","GoogleNews-vectors- 100%[===================>]   1.53G  97.6MB/s    in 19s     \n","\n","2021-02-21 22:18:17 (80.6 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n","\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.2)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bj2Qy9pO5zVx"},"source":["## HMM "]},{"cell_type":"markdown","metadata":{"id":"tU_hbYy4ELvr"},"source":["Define global variables"]},{"cell_type":"code","metadata":{"id":"x_UlxcGY6Wy8","executionInfo":{"status":"ok","timestamp":1613946006384,"user_tz":-330,"elapsed":137203,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}}},"source":["P_given = {}\n","P_given_freq = {} # (Tag, Tag)\n","\n","tag_freq = {} # Tag\n","\n","word_freq = {} # Word\n","word_tag_freq = {} # (Word, Tag)\n","word_tag_prob = {}\n","\n","vocab = set() # Words"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4cAIWNB3EcWI"},"source":["Process dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDvJnN4Mt3of","executionInfo":{"status":"ok","timestamp":1613946006385,"user_tz":-330,"elapsed":137194,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"4de13449-d547-4424-fb1a-23610f9c2ac3"},"source":["classes = [\"person\" ,\"product\", \"company\", \"geolocation\", \"movie\", \"music artist\", \"tvshow\", \"facility\", \"sports team\", \"other\"]\n","tmp_df = pd.read_table('NER-Dataset-10Types-Train.txt', names=[\"words\", \"tags\"], skip_blank_lines=False)\n","tag_set = list(set(tmp_df[\"tags\"]))[1:]\n","n_tags = len(tag_set)\n","\n","def process(dataset):\n","  print(\"\\n\", dataset)\n","  tmp_df = pd.read_table(dataset, names=[\"words\", \"tags\"], skip_blank_lines=False)\n","  print(tmp_df.head(10))\n","\n","  tag_set = list(set(tmp_df[\"tags\"]))[1:]\n","  n_tags = len(tag_set)\n","\n","  X = []\n","  Y = []\n","\n","  sentence = []\n","  tags = []\n","\n","  for word, t in zip(tmp_df[\"words\"], tmp_df[\"tags\"]):\n","    if word != word: # is NaN\n","      X.append(sentence)\n","      Y.append(tags)\n","      sentence = []\n","      tags = []\n","    else:\n","      sentence.append(word)\n","      tags.append(t)\n","  return X,Y\n","\n","Xt,Yt = process(\"NER-Dataset--TestSet.txt\")\n","datat = pd.DataFrame({\n","    'tokenized_sentences': Xt,\n","    'tags': Yt\n","})\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n"," NER-Dataset--TestSet.txt\n","             words  tags\n","0  @SammieLynnsMom   NaN\n","1         @tg1.781   NaN\n","2             they   NaN\n","3             will   NaN\n","4               be   NaN\n","5              all   NaN\n","6             done   NaN\n","7               by   NaN\n","8           Sunday   NaN\n","9            trust   NaN\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W-IMJsuOEQcJ"},"source":["Utility functions"]},{"cell_type":"code","metadata":{"id":"eYHIV0CK6dk_","executionInfo":{"status":"ok","timestamp":1613946006386,"user_tz":-330,"elapsed":137192,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}}},"source":["def process_sentence(sent, tags):\n","  for word in sent:\n","    vocab.add(word)\n","    word_freq[word] = word_freq.get(word, 0) + 1\n","\n","  for idx, (word, tag) in enumerate(zip(sent, tags)):\n","    tag_freq[tag] = tag_freq.get(tag, 0) + 1\n","    word_tag_freq[(word,tag)] = word_tag_freq.get((word,tag), 0) + 1\n","    if (idx > 0):\n","      prev_tag = tags[idx - 1]\n","      P_given_freq[(tag, prev_tag)] = P_given_freq.get( (tag, prev_tag), 0) + 1\n","\n","def get_word_tag_prob(word, tag):\n","\tif word not in vocab:\n","\t\tfor tag in tag_set:\n","\t\t\tword_tag_prob[word, tag] = 1.0 / len(tag_set)\n","\t\tvocab.add(word)\n","\n","\treturn word_tag_prob.get((word, tag), 0)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oxRHC--8EVsm"},"source":["Training function"]},{"cell_type":"code","metadata":{"id":"bps1YLdu6lxW","executionInfo":{"status":"ok","timestamp":1613946006387,"user_tz":-330,"elapsed":137190,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}}},"source":["def train(data):\n","  for sent, tags in zip(data['tokenized_sentences'], data['tags']):\n","    process_sentence(sent, tags)\n","\n","  for prev_tag in tag_set:\n","    for cur_tag in tag_set:\n","      if prev_tag not in tag_freq:\n","        P_given[cur_tag, prev_tag] = 1.0 / len(tag_set)\n","      else:\n","        try:\n","          P_given[cur_tag, prev_tag] = P_given_freq[cur_tag, prev_tag] / tag_freq[prev_tag]\n","        except KeyError:\n","          P_given[cur_tag, prev_tag] = 0\n","\n","  for word in vocab:\n","    for tag in tag_set:\n","      try:\n","        word_tag_prob[word, tag] = word_tag_freq[word, tag] / word_freq[word]\n","      except KeyError:\n","        word_tag_prob[word, tag] = 0"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYUEwz7KEYb9"},"source":["Prediction function"]},{"cell_type":"code","metadata":{"id":"786dFEUF6n1x","executionInfo":{"status":"ok","timestamp":1613946006387,"user_tz":-330,"elapsed":137189,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}}},"source":["def predict(sent):\n","\tprev_state = {}\n","\tP = {}\n","\tfor idx, word in enumerate(sent):\n","\t\tP_new = {}\n","\t\tif idx == 0:\n","\t\t\tfor cur_tag in tag_set:\n","\t\t\t\tP_new[cur_tag] = get_word_tag_prob(word, cur_tag)\n","\t\telse:\n","\t\t\tfor prev_tag in tag_set:\n","\t\t\t\tfor cur_tag in tag_set:\n","\t\t\t\t\t# How may cur_tag occur after prev_tag?\n","\t\t\t\t\tprob = P[prev_tag]\n","\t\t\t\t\tprob *= P_given.get( (cur_tag, prev_tag), 0)  # get_P_given(cur_tag, prev_tag)\n","\t\t\t\t\tprob *= get_word_tag_prob(word, cur_tag)\n","\n","\t\t\t\t\tif cur_tag not in P_new or prob > P_new[cur_tag]:\n","\t\t\t\t\t\tP_new[cur_tag] = prob\n","\t\t\t\t\t\tprev_state[cur_tag, idx] = prev_tag\n","\t\tP = P_new\n","\t\n","\tfinal_tag = None\n","\tfor tag in tag_set:\n","\t\tif final_tag is None or P[tag] > P[final_tag]:\n","\t\t\tfinal_tag = tag\n","      \n","\tpred = []\n","\tpred.append(final_tag)\n","\tcur_tag = final_tag\n","\tfor idx in range(len(sent) - 1, 0, -1):\n","\t\tcur_tag = prev_state[cur_tag, idx]\n","\t\tpred.append(cur_tag)\n","\t\n","\tpred.reverse()\n","\treturn pred"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SKahwHa6EetD"},"source":["Main 5-fold training"]},{"cell_type":"markdown","metadata":{"id":"oIE6zbDMU6Px"},"source":["## Train on NER-Dataset-Train.txt"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUS92KAqVML7","executionInfo":{"status":"ok","timestamp":1613946013614,"user_tz":-330,"elapsed":144404,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"d763a675-61e7-4519-8574-c9b979b1593b"},"source":["max_accuracy = 0\n","classification_repo = {}\n","predt = []\n","X, Y = process('NER-Dataset-Train.txt')\n","data = pd.DataFrame({\n","    'tokenized_sentences': X,\n","    'tags': Y\n","})\n","print(data.head())\n","# prepare cross validation\n","kfold = KFold(5, True, 1)\n","final_prediction = []\n","\n","# enumerate splits\n","for trn, test in kfold.split(data):\n","  \n","  # clear previous runs\n","  word_freq.clear()\n","  tag_freq.clear()\n","  word_tag_freq.clear()\n","  vocab.clear()\n","  P_given_freq.clear()\n","  word_tag_prob.clear()\n","  P_given.clear()\n","\n","  pred_labels = [] \n","  true_labels = [] \n","\n","  # train model for current fold\n","  train(data.iloc[trn])\n","  \n","  # validation for current fold\n","  for idx, row in data.iloc[test].iterrows():\n","    pred_labels.append( list( predict(row['tokenized_sentences'] )) )\n","    true_labels.append(list(row['tags']))\n","  \n","  accuracy = accuracy_score(true_labels, pred_labels)\n","  print(\"\\n\\n####################################################################################################################################\")\n","  print(\"Train Sample Size \\t: \", len(trn))\n","  print(\"Test Sample Size \\t: \", len(test))\n","  # print(\"Classification Report:\\n\", classification_report(true_labels, pred_labels))\n","  print(\"Accuracy: \", accuracy)\n","  print(\"F1 Score: \", f1_score(true_labels, pred_labels))\n","  print(\"Precision Score:\", precision_score(true_labels, pred_labels))\n","  print(\"Recall Score:\", recall_score(true_labels, pred_labels))\n","\n","  print(\"\\nTransition probability\\n\")\n","  trans_prob = np.zeros( (n_tags, n_tags))\n","  for i in range(n_tags):\n","    for j in range(n_tags):\n","      trans_prob[i][j] = P_given.get((tag_set[i], tag_set[j]), 0)\n","\n","  trans_prob_df = pd.DataFrame( trans_prob, columns=tag_set)\n","  trans_prob_df.index = tag_set\n","  pd.set_option(\"display.precision\", 2)\n","  print(trans_prob_df)\n","\n","\n","  print(\"\\nEmission probability\\n\")\n","  emission_prob = np.zeros( (len(vocab), n_tags))\n","  vocab_list = list(vocab)\n","  for i in range(len(vocab_list)):\n","    for j in range(n_tags):\n","      emission_prob[i][j] = word_tag_prob.get(( vocab_list[i], tag_set[j]), 0)\n","\n","  emission_prob_df = pd.DataFrame( emission_prob, columns=tag_set)\n","  emission_prob_df.index = vocab_list\n","  pd.set_option(\"display.precision\", 2)\n","  print(emission_prob_df)\n","\n","  print(\"####################################################################################################################################\\n\")\n","\n","  if accuracy > max_accuracy:\n","    max_accuracy = accuracy    \n","    classification_repo= classification_report(true_labels, pred_labels)\n","    predt = []\n","    for idx, row in datat.iterrows():\n","      predt.append( list( predict(row['tokenized_sentences'] )) )\n","    \n","f = open(\"output-HMM-NER-Dataset-Train.txt\", 'w')\n","for pred in predt:\n","  for x in pred:\n","    f.write(x+\"\\n\")\n","  f.write(\"\\n\")\n","f.close()\n","\n","print(\"Max Accuracy : \", max_accuracy, \")\")\n","print(\"Classification report\", classification_repo)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n"," NER-Dataset-Train.txt\n","         words tags\n","0  @LewisDixon    O\n","1        Trust    O\n","2           me    O\n","3            !    O\n","4           im    O\n","5        gonna    O\n","6           be    O\n","7     bringing    O\n","8          out    O\n","9        music    O\n","                                 tokenized_sentences                                               tags\n","0  [@LewisDixon, Trust, me, !, im, gonna, be, bri...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","1  [@joshHnumber1fan, its, okay, then, .., make, ...                  [O, O, O, O, O, O, O, O, O, O, O]\n","2  [Asprin, ,, check, ,, cup, of, tea, ,, check, ...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","3  [@angelportugues, LMAO, !, When, is, tht, one,...                     [O, O, O, O, O, O, O, O, O, O]\n","4  [The, Basic, Step, Before, You, Even, Start, T...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.7521008403361344\n","F1 Score:  0.0\n","Precision Score: 0.0\n","Recall Score: 0.0\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.05      0.05  ...           0.05      0.05\n","I-person            0.05      0.05  ...           0.05      0.05\n","I-musicartist       0.05      0.05  ...           0.05      0.05\n","B-tvshow            0.05      0.05  ...           0.05      0.05\n","B-person            0.05      0.05  ...           0.05      0.05\n","I-other             0.05      0.05  ...           0.05      0.05\n","B-company           0.05      0.05  ...           0.05      0.05\n","B-movie             0.05      0.05  ...           0.05      0.05\n","O                   0.05      0.05  ...           0.05      0.05\n","B-facility          0.05      0.05  ...           0.05      0.05\n","I-facility          0.05      0.05  ...           0.05      0.05\n","I-product           0.05      0.05  ...           0.05      0.05\n","I-movie             0.05      0.05  ...           0.05      0.05\n","I-company           0.05      0.05  ...           0.05      0.05\n","B-geo-loc           0.05      0.05  ...           0.05      0.05\n","B-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-product           0.05      0.05  ...           0.05      0.05\n","B-other             0.05      0.05  ...           0.05      0.05\n","I-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-musicartist       0.05      0.05  ...           0.05      0.05\n","I-tvshow            0.05      0.05  ...           0.05      0.05\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.05      0.05  ...           0.05      0.05\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.8529411764705882\n","F1 Score:  0.0\n","Precision Score: 0.0\n","Recall Score: 0.0\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.05      0.05  ...           0.05      0.05\n","I-person            0.05      0.05  ...           0.05      0.05\n","I-musicartist       0.05      0.05  ...           0.05      0.05\n","B-tvshow            0.05      0.05  ...           0.05      0.05\n","B-person            0.05      0.05  ...           0.05      0.05\n","I-other             0.05      0.05  ...           0.05      0.05\n","B-company           0.05      0.05  ...           0.05      0.05\n","B-movie             0.05      0.05  ...           0.05      0.05\n","O                   0.05      0.05  ...           0.05      0.05\n","B-facility          0.05      0.05  ...           0.05      0.05\n","I-facility          0.05      0.05  ...           0.05      0.05\n","I-product           0.05      0.05  ...           0.05      0.05\n","I-movie             0.05      0.05  ...           0.05      0.05\n","I-company           0.05      0.05  ...           0.05      0.05\n","B-geo-loc           0.05      0.05  ...           0.05      0.05\n","B-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-product           0.05      0.05  ...           0.05      0.05\n","B-other             0.05      0.05  ...           0.05      0.05\n","I-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-musicartist       0.05      0.05  ...           0.05      0.05\n","I-tvshow            0.05      0.05  ...           0.05      0.05\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.05      0.05  ...           0.05      0.05\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.05      0.05  ...           0.05      0.05\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.8315040047463661\n","F1 Score:  0.0\n","Precision Score: 0.0\n","Recall Score: 0.0\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.05      0.05  ...           0.05      0.05\n","I-person            0.05      0.05  ...           0.05      0.05\n","I-musicartist       0.05      0.05  ...           0.05      0.05\n","B-tvshow            0.05      0.05  ...           0.05      0.05\n","B-person            0.05      0.05  ...           0.05      0.05\n","I-other             0.05      0.05  ...           0.05      0.05\n","B-company           0.05      0.05  ...           0.05      0.05\n","B-movie             0.05      0.05  ...           0.05      0.05\n","O                   0.05      0.05  ...           0.05      0.05\n","B-facility          0.05      0.05  ...           0.05      0.05\n","I-facility          0.05      0.05  ...           0.05      0.05\n","I-product           0.05      0.05  ...           0.05      0.05\n","I-movie             0.05      0.05  ...           0.05      0.05\n","I-company           0.05      0.05  ...           0.05      0.05\n","B-geo-loc           0.05      0.05  ...           0.05      0.05\n","B-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-product           0.05      0.05  ...           0.05      0.05\n","B-other             0.05      0.05  ...           0.05      0.05\n","I-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-musicartist       0.05      0.05  ...           0.05      0.05\n","I-tvshow            0.05      0.05  ...           0.05      0.05\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.05      0.05  ...           0.05      0.05\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.7847370021283064\n","F1 Score:  0.0\n","Precision Score: 0.0\n","Recall Score: 0.0\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.05      0.05  ...           0.05      0.05\n","I-person            0.05      0.05  ...           0.05      0.05\n","I-musicartist       0.05      0.05  ...           0.05      0.05\n","B-tvshow            0.05      0.05  ...           0.05      0.05\n","B-person            0.05      0.05  ...           0.05      0.05\n","I-other             0.05      0.05  ...           0.05      0.05\n","B-company           0.05      0.05  ...           0.05      0.05\n","B-movie             0.05      0.05  ...           0.05      0.05\n","O                   0.05      0.05  ...           0.05      0.05\n","B-facility          0.05      0.05  ...           0.05      0.05\n","I-facility          0.05      0.05  ...           0.05      0.05\n","I-product           0.05      0.05  ...           0.05      0.05\n","I-movie             0.05      0.05  ...           0.05      0.05\n","I-company           0.05      0.05  ...           0.05      0.05\n","B-geo-loc           0.05      0.05  ...           0.05      0.05\n","B-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-product           0.05      0.05  ...           0.05      0.05\n","B-other             0.05      0.05  ...           0.05      0.05\n","I-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-musicartist       0.05      0.05  ...           0.05      0.05\n","I-tvshow            0.05      0.05  ...           0.05      0.05\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.05      0.05  ...           0.05      0.05\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.05      0.05  ...           0.05      0.05\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.05      0.05  ...           0.05      0.05\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.770839469808542\n","F1 Score:  0.0\n","Precision Score: 0.0\n","Recall Score: 0.0\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.05      0.05  ...           0.05      0.05\n","I-person            0.05      0.05  ...           0.05      0.05\n","I-musicartist       0.05      0.05  ...           0.05      0.05\n","B-tvshow            0.05      0.05  ...           0.05      0.05\n","B-person            0.05      0.05  ...           0.05      0.05\n","I-other             0.05      0.05  ...           0.05      0.05\n","B-company           0.05      0.05  ...           0.05      0.05\n","B-movie             0.05      0.05  ...           0.05      0.05\n","O                   0.05      0.05  ...           0.05      0.05\n","B-facility          0.05      0.05  ...           0.05      0.05\n","I-facility          0.05      0.05  ...           0.05      0.05\n","I-product           0.05      0.05  ...           0.05      0.05\n","I-movie             0.05      0.05  ...           0.05      0.05\n","I-company           0.05      0.05  ...           0.05      0.05\n","B-geo-loc           0.05      0.05  ...           0.05      0.05\n","B-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-product           0.05      0.05  ...           0.05      0.05\n","B-other             0.05      0.05  ...           0.05      0.05\n","I-sportsteam        0.05      0.05  ...           0.05      0.05\n","B-musicartist       0.05      0.05  ...           0.05      0.05\n","I-tvshow            0.05      0.05  ...           0.05      0.05\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.05      0.05  ...           0.05      0.05\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","Max Accuracy :  0.8529411764705882 )\n","Classification report               precision    recall  f1-score   support\n","\n","           _       0.00      0.00      0.00        78\n","     geo-loc       0.00      0.00      0.00         0\n","\n","   micro avg       0.00      0.00      0.00        78\n","   macro avg       0.00      0.00      0.00        78\n","weighted avg       0.00      0.00      0.00        78\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OPpFCKIQVdnA"},"source":["## Train on NER-Dataset-10Types-Train.txt"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kv7GW78yVdyG","executionInfo":{"status":"ok","timestamp":1613946021519,"user_tz":-330,"elapsed":152301,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"f61fc4b0-4b0e-4f5c-cbd1-7a4539cb25f1"},"source":["max_accuracy = 0\n","classification_repo = {}\n","predt = []\n","\n","X10, Y10 = process(\"NER-Dataset-10Types-Train.txt\")\n","data10 = pd.DataFrame({\n","    'tokenized_sentences': X10,\n","    'tags': Y10\n","})\n","print(data10.head())\n","# prepare cross validation\n","kfold = KFold(5, True, 1)\n","final_prediction = []\n","\n","# enumerate splits\n","for trn, test in kfold.split(data10):\n","  \n","  # clear previous runs\n","  word_freq.clear()\n","  tag_freq.clear()\n","  word_tag_freq.clear()\n","  vocab.clear()\n","  P_given_freq.clear()\n","  word_tag_prob.clear()\n","  P_given.clear()\n","\n","  pred_labels = [] \n","  true_labels = [] \n","\n","  # train model for current fold\n","  train(data10.iloc[trn])\n","  \n","  # validation for current fold\n","  for idx, row in data10.iloc[test].iterrows():\n","    pred_labels.append( list( predict(row['tokenized_sentences'] )) )\n","    true_labels.append(list(row['tags']))\n","  \n","  accuracy = accuracy_score(true_labels, pred_labels)\n","  print(\"\\n\\n####################################################################################################################################\")\n","  print(\"Train Sample Size \\t: \", len(trn))\n","  print(\"Test Sample Size \\t: \", len(test))\n","  # print(\"Classification Report:\\n\", classification_report(true_labels, pred_labels))\n","  print(\"Accuracy: \", accuracy)\n","  print(\"F1 Score: \", f1_score(true_labels, pred_labels))\n","  print(\"Precision Score:\", precision_score(true_labels, pred_labels))\n","  print(\"Recall Score:\", recall_score(true_labels, pred_labels))\n","\n","  print(\"\\nTransition probability\\n\")\n","  trans_prob = np.zeros( (n_tags, n_tags))\n","  for i in range(n_tags):\n","    for j in range(n_tags):\n","      trans_prob[i][j] = P_given.get((tag_set[i], tag_set[j]), 0)\n","\n","  trans_prob_df = pd.DataFrame( trans_prob, columns=tag_set)\n","  trans_prob_df.index = tag_set\n","  pd.set_option(\"display.precision\", 2)\n","  print(trans_prob_df)\n","\n","\n","  print(\"\\nEmission probability\\n\")\n","  emission_prob = np.zeros( (len(vocab), n_tags))\n","  vocab_list = list(vocab)\n","  for i in range(len(vocab_list)):\n","    for j in range(n_tags):\n","      emission_prob[i][j] = word_tag_prob.get(( vocab_list[i], tag_set[j]), 0)\n","\n","  emission_prob_df = pd.DataFrame( emission_prob, columns=tag_set)\n","  emission_prob_df.index = vocab_list\n","  pd.set_option(\"display.precision\", 2)\n","  print(emission_prob_df)\n","\n","  print(\"####################################################################################################################################\\n\")\n","\n","  if accuracy > max_accuracy:\n","    max_accuracy = accuracy    \n","    classification_repo= classification_report(true_labels, pred_labels)\n","    predt = []\n","    for idx, row in datat.iterrows():\n","      predt.append( list( predict(row['tokenized_sentences'] )) )\n","    \n","f = open(\"output-HMM-NER-Dataset-Train10types.txt\", 'w')\n","for pred in predt:\n","  for x in pred:\n","    f.write(x+\"\\n\")\n","  f.write(\"\\n\")\n","f.close()\n","\n","print(\"Max Accuracy : \", max_accuracy, \")\")\n","print(\"Classification report\", classification_repo)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\n"," NER-Dataset-10Types-Train.txt\n","         words tags\n","0  @LewisDixon    O\n","1        Trust    O\n","2           me    O\n","3            !    O\n","4           im    O\n","5        gonna    O\n","6           be    O\n","7     bringing    O\n","8          out    O\n","9        music    O\n","                                 tokenized_sentences                                               tags\n","0  [@LewisDixon, Trust, me, !, im, gonna, be, bri...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","1  [@joshHnumber1fan, its, okay, then, .., make, ...                  [O, O, O, O, O, O, O, O, O, O, O]\n","2  [Asprin, ,, check, ,, cup, of, tea, ,, check, ...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","3  [@angelportugues, LMAO, !, When, is, tht, one,...                     [O, O, O, O, O, O, O, O, O, O]\n","4  [The, Basic, Step, Before, You, Even, Start, T...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.907563025210084\n","F1 Score:  0.1862348178137652\n","Precision Score: 0.2\n","Recall Score: 0.17424242424242425\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.24      0.00  ...           0.00       0.0\n","I-person            0.00      0.10  ...           0.00       0.0\n","I-musicartist       0.00      0.00  ...           0.76       0.0\n","B-tvshow            0.00      0.00  ...           0.00       0.0\n","B-person            0.00      0.00  ...           0.00       0.0\n","I-other             0.00      0.00  ...           0.00       0.0\n","B-company           0.00      0.00  ...           0.00       0.0\n","B-movie             0.00      0.00  ...           0.00       0.0\n","O                   0.76      0.84  ...           0.24       0.8\n","B-facility          0.00      0.00  ...           0.00       0.0\n","I-facility          0.00      0.00  ...           0.00       0.0\n","I-product           0.00      0.00  ...           0.00       0.0\n","I-movie             0.00      0.00  ...           0.00       0.0\n","I-company           0.00      0.00  ...           0.00       0.0\n","B-geo-loc           0.00      0.00  ...           0.00       0.0\n","B-sportsteam        0.00      0.00  ...           0.00       0.0\n","B-product           0.00      0.00  ...           0.00       0.0\n","B-other             0.00      0.00  ...           0.00       0.0\n","I-sportsteam        0.00      0.00  ...           0.00       0.0\n","B-musicartist       0.00      0.00  ...           0.00       0.0\n","I-tvshow            0.00      0.00  ...           0.00       0.2\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.05      0.05  ...           0.05      0.05\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.9276710684273709\n","F1 Score:  0.1627906976744186\n","Precision Score: 0.14893617021276595\n","Recall Score: 0.1794871794871795\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.14      0.00  ...           0.00      0.00\n","I-person            0.00      0.03  ...           0.00      0.00\n","I-musicartist       0.00      0.00  ...           0.65      0.00\n","B-tvshow            0.00      0.00  ...           0.00      0.00\n","B-person            0.00      0.00  ...           0.00      0.00\n","I-other             0.00      0.00  ...           0.00      0.00\n","B-company           0.00      0.00  ...           0.00      0.00\n","B-movie             0.00      0.00  ...           0.00      0.00\n","O                   0.86      0.90  ...           0.35      0.75\n","B-facility          0.00      0.00  ...           0.00      0.00\n","I-facility          0.00      0.00  ...           0.00      0.00\n","I-product           0.00      0.00  ...           0.00      0.00\n","I-movie             0.00      0.00  ...           0.00      0.00\n","I-company           0.00      0.00  ...           0.00      0.00\n","B-geo-loc           0.00      0.00  ...           0.00      0.00\n","B-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-product           0.00      0.00  ...           0.00      0.00\n","B-other             0.00      0.00  ...           0.00      0.00\n","I-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-musicartist       0.00      0.00  ...           0.00      0.00\n","I-tvshow            0.00      0.00  ...           0.00      0.25\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.05      0.05  ...           0.05      0.05\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.05      0.05  ...           0.05      0.05\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.9279145654108573\n","F1 Score:  0.10426540284360189\n","Precision Score: 0.09166666666666666\n","Recall Score: 0.12087912087912088\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.26      0.00  ...           0.00      0.00\n","I-person            0.00      0.10  ...           0.00      0.00\n","I-musicartist       0.00      0.00  ...           0.75      0.00\n","B-tvshow            0.00      0.00  ...           0.00      0.00\n","B-person            0.00      0.00  ...           0.00      0.00\n","I-other             0.00      0.00  ...           0.00      0.00\n","B-company           0.00      0.00  ...           0.00      0.00\n","B-movie             0.00      0.00  ...           0.00      0.00\n","O                   0.74      0.85  ...           0.25      0.71\n","B-facility          0.00      0.00  ...           0.00      0.00\n","I-facility          0.00      0.00  ...           0.00      0.00\n","I-product           0.00      0.00  ...           0.00      0.00\n","I-movie             0.00      0.00  ...           0.00      0.00\n","I-company           0.00      0.00  ...           0.00      0.00\n","B-geo-loc           0.00      0.00  ...           0.00      0.00\n","B-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-product           0.00      0.00  ...           0.00      0.00\n","B-other             0.00      0.00  ...           0.00      0.00\n","I-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-musicartist       0.00      0.00  ...           0.00      0.00\n","I-tvshow            0.00      0.00  ...           0.00      0.29\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.05      0.05  ...           0.05      0.05\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.9182122225600486\n","F1 Score:  0.15517241379310345\n","Precision Score: 0.16363636363636364\n","Recall Score: 0.14754098360655737\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.29      0.00  ...           0.00       0.0\n","I-person            0.00      0.11  ...           0.00       0.0\n","I-musicartist       0.00      0.00  ...           0.76       0.0\n","B-tvshow            0.00      0.00  ...           0.00       0.0\n","B-person            0.00      0.00  ...           0.00       0.0\n","I-other             0.00      0.00  ...           0.00       0.0\n","B-company           0.00      0.00  ...           0.00       0.0\n","B-movie             0.00      0.00  ...           0.00       0.0\n","O                   0.71      0.84  ...           0.24       0.8\n","B-facility          0.00      0.00  ...           0.00       0.0\n","I-facility          0.00      0.00  ...           0.00       0.0\n","I-product           0.00      0.00  ...           0.00       0.0\n","I-movie             0.00      0.00  ...           0.00       0.0\n","I-company           0.00      0.00  ...           0.00       0.0\n","B-geo-loc           0.00      0.00  ...           0.00       0.0\n","B-sportsteam        0.00      0.00  ...           0.00       0.0\n","B-product           0.00      0.00  ...           0.00       0.0\n","B-other             0.00      0.00  ...           0.00       0.0\n","I-sportsteam        0.00      0.00  ...           0.00       0.0\n","B-musicartist       0.00      0.00  ...           0.00       0.0\n","I-tvshow            0.00      0.00  ...           0.00       0.2\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.05      0.05  ...           0.05      0.05\n","Engineers                  0.00      0.00  ...           0.00      0.00\n","moments                    0.05      0.05  ...           0.05      0.05\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.05      0.05  ...           0.05      0.05\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Accuracy:  0.8868924889543446\n","F1 Score:  0.11814345991561181\n","Precision Score: 0.1320754716981132\n","Recall Score: 0.10687022900763359\n","\n","Transition probability\n","\n","               I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","I-geo-loc           0.22      0.00  ...           0.00      0.00\n","I-person            0.00      0.10  ...           0.00      0.00\n","I-musicartist       0.00      0.00  ...           0.71      0.00\n","B-tvshow            0.00      0.00  ...           0.00      0.00\n","B-person            0.00      0.00  ...           0.00      0.00\n","I-other             0.00      0.00  ...           0.00      0.00\n","B-company           0.00      0.00  ...           0.00      0.00\n","B-movie             0.00      0.00  ...           0.00      0.00\n","O                   0.78      0.87  ...           0.29      0.71\n","B-facility          0.00      0.00  ...           0.00      0.00\n","I-facility          0.00      0.00  ...           0.00      0.00\n","I-product           0.00      0.00  ...           0.00      0.00\n","I-movie             0.00      0.00  ...           0.00      0.00\n","I-company           0.00      0.00  ...           0.00      0.00\n","B-geo-loc           0.00      0.00  ...           0.00      0.00\n","B-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-product           0.00      0.00  ...           0.00      0.00\n","B-other             0.00      0.00  ...           0.00      0.00\n","I-sportsteam        0.00      0.00  ...           0.00      0.00\n","B-musicartist       0.00      0.00  ...           0.00      0.00\n","I-tvshow            0.00      0.00  ...           0.00      0.29\n","\n","[21 rows x 21 columns]\n","\n","Emission probability\n","\n","                      I-geo-loc  I-person  ...  B-musicartist  I-tvshow\n","@dolemite4                 0.00      0.00  ...           0.00      0.00\n","Engineers                  0.05      0.05  ...           0.05      0.05\n","moments                    0.00      0.00  ...           0.00      0.00\n","December                   0.00      0.00  ...           0.00      0.00\n","Brothers                   0.00      0.00  ...           0.00      0.00\n","...                         ...       ...  ...            ...       ...\n","Jaybilizer                 0.00      0.00  ...           0.00      0.00\n","*kisses                    0.00      0.00  ...           0.00      0.00\n","http://bit.ly/94sBNr       0.00      0.00  ...           0.00      0.00\n","jail                       0.00      0.00  ...           0.00      0.00\n","http://bit.ly/9XQgSr       0.00      0.00  ...           0.00      0.00\n","\n","[5080 rows x 21 columns]\n","####################################################################################################################################\n","\n","Max Accuracy :  0.9279145654108573 )\n","Classification report               precision    recall  f1-score   support\n","\n","     company       0.17      0.14      0.15         7\n","    facility       0.50      0.10      0.17        10\n","     geo-loc       0.20      0.05      0.08        21\n","       movie       0.00      0.00      0.00         3\n"," musicartist       0.00      0.00      0.00         2\n","       other       0.33      0.11      0.17         9\n","      person       0.78      0.24      0.37        29\n","     product       0.00      0.00      0.00         9\n","  sportsteam       0.00      0.00      0.00         0\n","      tvshow       0.00      0.00      0.00         1\n","\n","   micro avg       0.09      0.12      0.10        91\n","   macro avg       0.20      0.06      0.09        91\n","weighted avg       0.39      0.12      0.18        91\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9ZNILBz7OHif"},"source":["# RNN-Vanilla, GRU, LSTM"]},{"cell_type":"code","metadata":{"id":"qxMkEspFsH7u","executionInfo":{"status":"ok","timestamp":1613948612422,"user_tz":-330,"elapsed":1025,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}}},"source":["\r\n","def func1(dataset, metrics=False, variant=\"LSTM\"):\r\n","  max_accuracy = 0\r\n","  df = pd.read_table(f\"/content/{dataset}\", names=[\"words\", \"tags\"], skip_blank_lines=False)\r\n","  sentences = []\r\n","  tags = []\r\n","\r\n","  sen = []\r\n","  ta = []\r\n","\r\n","  for word, t in zip(df[\"words\"], df[\"tags\"]):\r\n","    if word != word: # is NaN\r\n","      sentences.append(sen)\r\n","      tags.append(ta)\r\n","      sen = []\r\n","      ta = []\r\n","    else:\r\n","      sen.append(word)\r\n","      ta.append(t)\r\n","\r\n","\r\n","  MAX_SEQ_LENGTH = 8\r\n","  X_padded = pad_sequences(sentences, maxlen=MAX_SEQ_LENGTH, padding=\"post\", truncating=\"post\", value=\"O\", dtype=object)\r\n","  Y_padded = pad_sequences(tags, maxlen=MAX_SEQ_LENGTH, padding=\"post\", truncating=\"post\", value=\"O\", dtype=object)\r\n","\r\n","  X = []\r\n","  for sen in X_padded:\r\n","    sentence = []\r\n","    for word in sen:\r\n","      if word in word2vec:\r\n","        sentence.append(np.asarray(word2vec[word]).astype(np.float32))\r\n","      else:\r\n","        sentence.append(np.zeros(300).astype(np.float32))\r\n","    X.append(np.array(sentence).tolist())\r\n","\r\n","\r\n","  tag_encode = {}\r\n","  tag_decode = {}\r\n","  all_tags = list(set(df[\"tags\"]))[1:]\r\n","  all_tags.append(\"O\") # padded tag\r\n","  all_tags = list(set(all_tags))\r\n","  number_of_tags = len(all_tags)\r\n","  for i, t in enumerate(all_tags):\r\n","    tag_encode[t] = i\r\n","    tag_decode[i] = t\r\n","\r\n","  Y = []\r\n","  for seq in Y_padded:\r\n","    tag_seq = []\r\n","    for t in seq:\r\n","      one_hot = [0] * number_of_tags\r\n","      one_hot[tag_encode.setdefault(t, tag_encode[\"O\"])] = 1\r\n","      tag_seq.append(np.array(one_hot, dtype=np.float))\r\n","    Y.append(np.array(tag_seq).tolist())\r\n","\r\n","  n_samples = len(X)\r\n","\r\n","  data = pd.DataFrame({\r\n","      'tokenized_sentences': X,\r\n","      'tags': Y\r\n","  })\r\n","  fold = 1\r\n","  kfold = KFold(5, True, 1)\r\n","  for trn, test in kfold.split(data):\r\n","    X_train = []\r\n","    X_test = []\r\n","    Y_train = []\r\n","    Y_test = []\r\n","    \r\n","    for idx,row in  data.iloc[trn].iterrows():\r\n","      X_train.append( np.array(row[\"tokenized_sentences\"]))\r\n","      Y_train.append( np.array(row[\"tags\"]))\r\n","    \r\n","    for idx,row in  data.iloc[test].iterrows():\r\n","      X_test.append( np.array(row[\"tokenized_sentences\"]))\r\n","      Y_test.append( np.array(row[\"tags\"]))\r\n","\r\n","    X_train = np.asarray(X_train)\r\n","    Y_train = np.asarray(Y_train)\r\n","    X_test = np.asarray(X_test)\r\n","    Y_test = np.asarray(Y_test)\r\n","\r\n","    VALID_SIZE = 0.15\r\n","    X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)\r\n","\r\n","    # create architecture\r\n","    model = Sequential()\r\n","    # add an RNN layer\r\n","    num_cells = 16\r\n","    if variant == \"LSTM\":\r\n","      model.add(LSTM(num_cells, \r\n","                    return_sequences=True,\r\n","                    input_shape=(MAX_SEQ_LENGTH, 300) # True - return whole sequence; False - return single output of the end of the sequence\r\n","      ))\r\n","    elif variant == \"Vanilla RNN\":\r\n","      model.add(SimpleRNN(num_cells, \r\n","                    return_sequences=True,\r\n","                    input_shape=(MAX_SEQ_LENGTH, 300) # True - return whole sequence; False - return single output of the end of the sequence\r\n","      ))\r\n","    elif variant == \"GRU\":\r\n","      model.add(GRU(num_cells, \r\n","                    return_sequences=True,\r\n","                    input_shape=(MAX_SEQ_LENGTH, 300) # True - return whole sequence; False - return single output of the end of the sequence\r\n","      ))\r\n","    # add time distributed (output aStart probability (π).t each sequence) layer\r\n","    model.add(TimeDistributed(Dense(number_of_tags, activation='softmax')))\r\n","    model.compile(loss = 'categorical_crossentropy', optimizer =  'adam', metrics = ['acc'])\r\n","\r\n","\r\n","    training = model.fit(X_train, Y_train, batch_size=4, epochs=50, validation_data=(X_validation, Y_validation), verbose=0)\r\n","    Y_pred = model.predict(X_test)\r\n","\r\n","    true_labels = []\r\n","    for i in range(Y_test.shape[0]):\r\n","      labels = []\r\n","      for j in range(Y_test.shape[1]):\r\n","        tag = np.argmax(Y_test[i][j])\r\n","        assert tag <= number_of_tags\r\n","        labels.append( tag_decode[tag] )\r\n","      true_labels.append(labels)\r\n","    \r\n","    pred_labels = []\r\n","    unique_pred = set()\r\n","    for i in range(Y_pred.shape[0]):\r\n","      labels = []\r\n","      for j in range(Y_pred.shape[1]):\r\n","        tag = np.argmax(Y_pred[i][j])\r\n","        assert tag <= number_of_tags\r\n","        labels.append( tag_decode[tag] )\r\n","        unique_pred.add( tag_decode[tag] )\r\n","      pred_labels.append(labels)\r\n","    \r\n","    print(\"\\n\\n####################################################################################################################################\")\r\n","    print(\"Train Sample Size \\t: \", len(trn))\r\n","    print(\"Test Sample Size \\t: \", len(test))\r\n","    print(\"Fold\", fold, \"for\", variant)\r\n","    # print(\"Classification Report:\\n\", classification_report(true_labels, pred_labels))\r\n","    print(\"Accuracy: \", accuracy_score(true_labels, pred_labels))\r\n","    print(\"F1 Score: \", f1_score(true_labels, pred_labels))\r\n","    print(\"Precision Score:\", precision_score(true_labels, pred_labels))\r\n","    print(\"Recall Score:\", recall_score(true_labels, pred_labels))\r\n","    fold += 1\r\n","    print(\"####################################################################################################################################\")\r\n","\r\n","    if max_accuracy > accuracy_score(true_labels, pred_labels):\r\n","      max_accuracy = accuracy_score(true_labels, pred_labels)\r\n","\r\n","      # Evaluate the test set\r\n","      for test_file in [\"NER-Dataset--TestSet.txt\"]:\r\n","        df_test = pd.read_table(test_file, names=[\"words\"], skip_blank_lines=False)\r\n","        sentences = []\r\n","        tags = []\r\n","\r\n","        sen = []\r\n","        ta = []\r\n","\r\n","        for word in df_test[\"words\"]:\r\n","          if word != word: # is NaN\r\n","            sentences.append(sen)\r\n","            sen = []\r\n","          else:\r\n","            sen.append(word)\r\n","\r\n","        X_padded = pad_sequences(sentences, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\", value=\"O\", dtype=object)\r\n","        X = []\r\n","        for sen in X_padded:\r\n","          sentence = []\r\n","          for word in sen:\r\n","            if word in word2vec:\r\n","              sentence.append(np.asarray(word2vec[word]).astype(np.float32))\r\n","            else:\r\n","              sentence.append(np.zeros(300).astype(np.float32))\r\n","          X.append(np.array(sentence))\r\n","\r\n","        with open(\"output-{}-{}-trained_on_{}\".format(variant, test_file, dataset ), \"w\") as f:\r\n","          Y_pred = model.predict(np.array(X))\r\n","          for y, sen in zip(Y_pred, sentences):\r\n","            for t, word in zip(y, sen):\r\n","              f.write(str(word))\r\n","              f.write(\" \")\r\n","              index = np.argmax(t)\r\n","              f.write(all_tags[index])\r\n","              f.write(\"\\n\")\r\n","          f.write(\"\\n\")"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hE-29i2iWrde"},"source":["# Train on NER-Dataset-Train.txt"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2DesajVWnY8","executionInfo":{"status":"ok","timestamp":1613949094990,"user_tz":-330,"elapsed":480976,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"f12fb1ed-e36e-420a-d86a-1c554473901b"},"source":["types_of_RNN = [\"LSTM\",\"Vanilla RNN\", \"GRU\"]\n","for rnn in range(3):\n","  func1(\"NER-Dataset-Train.txt\", True, types_of_RNN[rnn])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for LSTM\n","Accuracy:  0.9417613636363636\n","F1 Score:  0.4273504273504274\n","Precision Score: 0.4807692307692308\n","Recall Score: 0.38461538461538464\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for LSTM\n","Accuracy:  0.9630681818181818\n","F1 Score:  0.4523809523809524\n","Precision Score: 0.4523809523809524\n","Recall Score: 0.4523809523809524\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for LSTM\n","Accuracy:  0.9495738636363636\n","F1 Score:  0.36781609195402304\n","Precision Score: 0.4\n","Recall Score: 0.3404255319148936\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for LSTM\n","Accuracy:  0.9609375\n","F1 Score:  0.5631067961165047\n","Precision Score: 0.6041666666666666\n","Recall Score: 0.5272727272727272\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for LSTM\n","Accuracy:  0.9488636363636364\n","F1 Score:  0.5272727272727272\n","Precision Score: 0.6041666666666666\n","Recall Score: 0.46774193548387094\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for Vanilla RNN\n","Accuracy:  0.9382102272727273\n","F1 Score:  0.38461538461538464\n","Precision Score: 0.38461538461538464\n","Recall Score: 0.38461538461538464\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for Vanilla RNN\n","Accuracy:  0.9566761363636364\n","F1 Score:  0.3333333333333333\n","Precision Score: 0.3333333333333333\n","Recall Score: 0.3333333333333333\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for Vanilla RNN\n","Accuracy:  0.9460227272727273\n","F1 Score:  0.37777777777777777\n","Precision Score: 0.3953488372093023\n","Recall Score: 0.3617021276595745\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for Vanilla RNN\n","Accuracy:  0.9509943181818182\n","F1 Score:  0.5321100917431193\n","Precision Score: 0.5370370370370371\n","Recall Score: 0.5272727272727272\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for Vanilla RNN\n","Accuracy:  0.9353693181818182\n","F1 Score:  0.3508771929824561\n","Precision Score: 0.38461538461538464\n","Recall Score: 0.3225806451612903\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for GRU\n","Accuracy:  0.9375\n","F1 Score:  0.36065573770491804\n","Precision Score: 0.38596491228070173\n","Recall Score: 0.3384615384615385\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for GRU\n","Accuracy:  0.9644886363636364\n","F1 Score:  0.4691358024691358\n","Precision Score: 0.48717948717948717\n","Recall Score: 0.4523809523809524\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for GRU\n","Accuracy:  0.9580965909090909\n","F1 Score:  0.46153846153846156\n","Precision Score: 0.4772727272727273\n","Recall Score: 0.44680851063829785\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for GRU\n","Accuracy:  0.9545454545454546\n","F1 Score:  0.584070796460177\n","Precision Score: 0.5689655172413793\n","Recall Score: 0.6\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for GRU\n","Accuracy:  0.9467329545454546\n","F1 Score:  0.4727272727272728\n","Precision Score: 0.5416666666666666\n","Recall Score: 0.41935483870967744\n","####################################################################################################################################\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3m6_DFsXWuR2"},"source":["# Train on NER-Dataset-10Types-Train.txt"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz05Kkd_QKeW","executionInfo":{"status":"ok","timestamp":1613949588307,"user_tz":-330,"elapsed":971073,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"5a158199-eb27-4ee2-e5d4-a7b431791179"},"source":["types_of_RNN = [\"LSTM\",\"Vanilla RNN\", \"GRU\"]\n","for rnn in range(3):\n","  func1(\"NER-Dataset-10Types-Train.txt\", True, types_of_RNN[rnn])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for LSTM\n","Accuracy:  0.9438920454545454\n","F1 Score:  0.375\n","Precision Score: 0.44680851063829785\n","Recall Score: 0.3230769230769231\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for LSTM\n","Accuracy:  0.9517045454545454\n","F1 Score:  0.26506024096385544\n","Precision Score: 0.2682926829268293\n","Recall Score: 0.2619047619047619\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for LSTM\n","Accuracy:  0.9580965909090909\n","F1 Score:  0.34666666666666673\n","Precision Score: 0.4642857142857143\n","Recall Score: 0.2765957446808511\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for LSTM\n","Accuracy:  0.9538352272727273\n","F1 Score:  0.40425531914893614\n","Precision Score: 0.48717948717948717\n","Recall Score: 0.34545454545454546\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for LSTM\n","Accuracy:  0.9438920454545454\n","F1 Score:  0.3838383838383838\n","Precision Score: 0.5135135135135135\n","Recall Score: 0.3064516129032258\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for Vanilla RNN\n","Accuracy:  0.9318181818181818\n","F1 Score:  0.34328358208955223\n","Precision Score: 0.3333333333333333\n","Recall Score: 0.35384615384615387\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for Vanilla RNN\n","Accuracy:  0.9517045454545454\n","F1 Score:  0.25882352941176473\n","Precision Score: 0.2558139534883721\n","Recall Score: 0.2619047619047619\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for Vanilla RNN\n","Accuracy:  0.9488636363636364\n","F1 Score:  0.2926829268292683\n","Precision Score: 0.34285714285714286\n","Recall Score: 0.2553191489361702\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for Vanilla RNN\n","Accuracy:  0.9446022727272727\n","F1 Score:  0.28828828828828823\n","Precision Score: 0.2857142857142857\n","Recall Score: 0.2909090909090909\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for Vanilla RNN\n","Accuracy:  0.9353693181818182\n","F1 Score:  0.3387096774193548\n","Precision Score: 0.3387096774193548\n","Recall Score: 0.3387096774193548\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 1 for GRU\n","Accuracy:  0.9375\n","F1 Score:  0.319327731092437\n","Precision Score: 0.35185185185185186\n","Recall Score: 0.2923076923076923\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 2 for GRU\n","Accuracy:  0.9559659090909091\n","F1 Score:  0.3170731707317073\n","Precision Score: 0.325\n","Recall Score: 0.30952380952380953\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 3 for GRU\n","Accuracy:  0.9524147727272727\n","F1 Score:  0.2891566265060241\n","Precision Score: 0.3333333333333333\n","Recall Score: 0.2553191489361702\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 4 for GRU\n","Accuracy:  0.9481534090909091\n","F1 Score:  0.3793103448275862\n","Precision Score: 0.36065573770491804\n","Recall Score: 0.4\n","####################################################################################################################################\n","\n","\n","####################################################################################################################################\n","Train Sample Size \t:  704\n","Test Sample Size \t:  176\n","Fold 5 for GRU\n","Accuracy:  0.9396306818181818\n","F1 Score:  0.4070796460176991\n","Precision Score: 0.45098039215686275\n","Recall Score: 0.3709677419354839\n","####################################################################################################################################\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKp3ZhAUX_j7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613947191285,"user_tz":-330,"elapsed":981,"user":{"displayName":"Rahul Grover","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg14fQHU6p-nDF7WL21Wl4rcUvwq4n9qgWKLmg92FY=s64","userId":"12270877931677686431"}},"outputId":"fb658eb6-a16d-432f-f02d-67a1426a178e"},"source":["!pwd"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eCUws8QPv7np"},"source":[""],"execution_count":null,"outputs":[]}]}