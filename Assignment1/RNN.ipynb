{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aF5sV98Y2PKl",
        "sS-M4L2U2PKp",
        "Pixvywi_2PKr"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m161WAY72PKX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "%matplotlib inline\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "JosdeNfL2PKa",
        "outputId": "9df92387-5a49-47c5-dffa-34dffdde9945"
      },
      "source": [
        "df = pd.read_csv('WSJ_treebank_corpus.csv')\n",
        "df[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_sentences</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Pierre', 'Vinken', ',', '61', 'years', 'old'...</td>\n",
              "      <td>['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Els...</td>\n",
              "      <td>['NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Rudolph', 'Agnew', ',', '55', 'years', 'old'...</td>\n",
              "      <td>['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', 'CC', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['A', 'form', 'of', 'asbestos', 'once', 'used'...</td>\n",
              "      <td>['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', '-NONE-'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['The', 'asbestos', 'fiber', ',', 'crocidolite...</td>\n",
              "      <td>['DT', 'NN', 'NN', ',', 'NN', ',', 'VBZ', 'RB'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>['Lorillard', 'Inc.', ',', 'the', 'unit', 'of'...</td>\n",
              "      <td>['NNP', 'NNP', ',', 'DT', 'NN', 'IN', 'JJ', 'J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>['Although', 'preliminary', 'findings', 'were'...</td>\n",
              "      <td>['IN', 'JJ', 'NNS', 'VBD', 'VBN', '-NONE-', 'R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>['A', 'Lorillard', 'spokewoman', 'said', ',', ...</td>\n",
              "      <td>['DT', 'NNP', 'NN', 'VBD', ',', '``', 'DT', 'V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>['We', \"'re\", 'talking', 'about', 'years', 'ag...</td>\n",
              "      <td>['PRP', 'VBP', 'VBG', 'IN', 'NNS', 'IN', 'IN',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>['There', 'is', 'no', 'asbestos', 'in', 'our',...</td>\n",
              "      <td>['EX', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NNS',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 tokenized_sentences                                               tags\n",
              "0  ['Pierre', 'Vinken', ',', '61', 'years', 'old'...  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'M...\n",
              "1  ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Els...  ['NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP'...\n",
              "2  ['Rudolph', 'Agnew', ',', '55', 'years', 'old'...  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', 'CC', '...\n",
              "3  ['A', 'form', 'of', 'asbestos', 'once', 'used'...  ['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', '-NONE-'...\n",
              "4  ['The', 'asbestos', 'fiber', ',', 'crocidolite...  ['DT', 'NN', 'NN', ',', 'NN', ',', 'VBZ', 'RB'...\n",
              "5  ['Lorillard', 'Inc.', ',', 'the', 'unit', 'of'...  ['NNP', 'NNP', ',', 'DT', 'NN', 'IN', 'JJ', 'J...\n",
              "6  ['Although', 'preliminary', 'findings', 'were'...  ['IN', 'JJ', 'NNS', 'VBD', 'VBN', '-NONE-', 'R...\n",
              "7  ['A', 'Lorillard', 'spokewoman', 'said', ',', ...  ['DT', 'NNP', 'NN', 'VBD', ',', '``', 'DT', 'V...\n",
              "8  ['We', \"'re\", 'talking', 'about', 'years', 'ag...  ['PRP', 'VBP', 'VBG', 'IN', 'NNS', 'IN', 'IN',...\n",
              "9  ['There', 'is', 'no', 'asbestos', 'in', 'our',...  ['EX', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NNS',..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7NYwkM72PKb"
      },
      "source": [
        "def strToVec(row):\n",
        "    row = row[1:-1]                               # removing the brackets\n",
        "    row = row.split(', ')                         # extracting individual tokens\n",
        "    return np.array([item[1:-1] for item in row])  # removing the single quotes, and returning an np array\n",
        "\n",
        "df['tokenized_sentences'] = df['tokenized_sentences'].apply(lambda row: strToVec(row))\n",
        "df['tags'] = df['tags'].apply(lambda row: strToVec(row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liTC-m_52PKd"
      },
      "source": [
        "unique_labels = set()\n",
        "for row in df['tags'].values.flatten():\n",
        "    for item in row:\n",
        "        unique_labels.add(item)\n",
        "unique_labels = np.array(list(unique_labels))\n",
        "remove_labels = ['``', '.', '$', ',', ':', \"''\", '#', 'CD']\n",
        "\n",
        "for label in remove_labels:\n",
        "    unique_labels = np.delete(unique_labels, np.where(unique_labels == label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3oa1rTR2PKe",
        "outputId": "04f556d7-5a93-4a1e-b73e-4b5a40a5e8a7"
      },
      "source": [
        "def removePuncLabels(x, y):\n",
        "    ans = []\n",
        "    for idx, item in enumerate(y):\n",
        "        if item not in remove_labels:\n",
        "            ans.append([x[idx], y[idx]])\n",
        "    return ans\n",
        "\n",
        "# Removing the following tags and corresponding tokens from the dataset\n",
        "df = [removePuncLabels(x, y) for x, y in zip(df['tokenized_sentences'], df['tags'])]\n",
        "df_back = np.copy(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, order=order, subok=subok, copy=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR0RN4pO2PKe"
      },
      "source": [
        "word2vec_path = '/home/rg99/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ_2Zscv2PKf"
      },
      "source": [
        "# initializing unknown token\n",
        "UNK = np.zeros(300)\n",
        "UNK[0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "N9YIYUUZ2PKf",
        "outputId": "8cf00f35-b2da-4bae-dfd9-47c2ee832d21"
      },
      "source": [
        "df = [ [ (model[pair[0]], pair[1]) if pair[0] in model.vocab else (UNK, pair[1]) for pair in row] for row in df]\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79u15s0y2PKg"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJfzwIg2PKg",
        "outputId": "a1cb3d6b-ee17-4e85-fde0-9514b150e40a"
      },
      "source": [
        "# zero-padd the dataset\n",
        "max_sequence_len = max([len(x) for x in df])\n",
        "max_sequence_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tnsk7g32PKh",
        "outputId": "e123c359-be3c-43e2-e8a2-855bb1635d4b"
      },
      "source": [
        "mean_sequence_len = np.mean([len(x) for x in df])\n",
        "mean_sequence_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.885794583546243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdjoQ5bV2PKh"
      },
      "source": [
        "pdd = [np.zeros(300), 'Padding']\n",
        "for idx, row in enumerate(df):\n",
        "    while (len(df[idx]) < max_sequence_len):\n",
        "        df[idx].append(pdd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi2OZJr32PKh",
        "outputId": "a8ff2d77-c1b7-45ea-91ed-5b034719d810"
      },
      "source": [
        "np.array(df).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3914, 178, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ej0zG12PKk",
        "outputId": "c06655b1-ee3e-451a-9e90-c5701ee22143"
      },
      "source": [
        "train_data = df[:2600]\r\n",
        "test_data  = df[2600:]\r\n",
        "data_in = np.array([[word[0] for word in row] for row in df])\r\n",
        "data_out = np.array([[word[1] for word in row] for row in df]).reshape((3914, 178, 1))\r\n",
        "data = zip(data_in, data_out)\r\n",
        "x_data = tf.constant(data_in)\r\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\r\n",
        "tokenizer.fit_on_texts(np.append(unique_labels, 'Padding'))\r\n",
        "tokenizer.texts_to_sequences([\"Padding\", \"PRP\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[37], [2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cCkZqJg2PKk",
        "outputId": "0e959ff0-a3ee-4e89-911d-b643b14c6341"
      },
      "source": [
        "y_data = tf.constant([[tokenizer.texts_to_sequences([word[0]])[0] for word in row] for row in data_out])\r\n",
        "np.array(data_out).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3914, 178, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF5sV98Y2PKl"
      },
      "source": [
        "## 1st "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBDGtn8V2PKm",
        "outputId": "2fce3812-17a0-4b2c-b0c9-94390378002e"
      },
      "source": [
        "X_train, X_test = x_data[:2600], x_data[2600:]\r\n",
        "y_train, y_test = y_data[:2600], y_data[2600:]\r\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2600, 178, 300]), TensorShape([2600, 178, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1ALFqOU2PKm",
        "outputId": "309cf638-8635-447a-b29d-ddfed256f1d0"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[max_sequence_len, 300], dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_sequence_len, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "82/82 [==============================] - 36s 441ms/step - loss: 1.2369 - accuracy: 0.8673\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 44s 540ms/step - loss: 0.3824 - accuracy: 0.8902\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 39s 473ms/step - loss: 0.3422 - accuracy: 0.9016\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 38s 466ms/step - loss: 0.2796 - accuracy: 0.9246\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 40s 486ms/step - loss: 0.2057 - accuracy: 0.9446\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 38s 464ms/step - loss: 0.1534 - accuracy: 0.9590\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 38s 467ms/step - loss: 0.1201 - accuracy: 0.9678\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 38s 464ms/step - loss: 0.0998 - accuracy: 0.9721\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 40s 492ms/step - loss: 0.0873 - accuracy: 0.9749\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 45s 546ms/step - loss: 0.0788 - accuracy: 0.9771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuUjyaRH2PKm",
        "outputId": "c87ccfc0-8759-4714-f91a-6a1219db1f30"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 3s 75ms/step - loss: 0.0663 - accuracy: 0.9799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06628849357366562, 0.9798668026924133]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elO_Nx5a2PKn",
        "outputId": "1809ffa8-04b7-493d-d213-59ccdc1e77a1"
      },
      "source": [
        "Y_pred_1 = model.predict_classes(X_test)\n",
        "Y_pred_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-47-fca154c38c1d>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21, 10, 36, ..., 37, 37, 37],\n",
              "       [24,  5, 21, ..., 37, 37, 37],\n",
              "       [24,  2,  5, ..., 37, 37, 37],\n",
              "       ...,\n",
              "       [ 9,  9,  9, ..., 37, 37, 37],\n",
              "       [19, 35, 24, ..., 37, 37, 37],\n",
              "       [ 9, 35, 23, ..., 37, 37, 37]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSfQBgkO2PKn",
        "outputId": "03c53618-8724-4aec-bc5e-b83a6a619558"
      },
      "source": [
        "Y_pred_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1314, 178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cjFAxqE2PKn",
        "outputId": "0b0d2e69-7fd6-46cc-8b07-40f88fe4c465"
      },
      "source": [
        "pad_marker = tokenizer.texts_to_sequences([\"Padding\"])[0][0]\n",
        "pad_marker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaXVFkBJ2PKo"
      },
      "source": [
        "def evaluate_accuracy(y_pred, y_true, y_original):\n",
        "    accuracy_sum = []\n",
        "    for counter, _tmp in enumerate(y_pred):\n",
        "        idx = 0\n",
        "        while idx != len(y_true[counter]) and y_true[counter][idx] != pad_marker:\n",
        "            idx += 1\n",
        "        \n",
        "        y_pred_ = y_pred[counter][:idx]\n",
        "        y_true_ = y_true[counter][:idx]\n",
        "\n",
        "        match_counter = 0\n",
        "        for idx, _ in enumerate(y_pred_):\n",
        "            if y_pred_[idx] == y_true_[idx]:\n",
        "                match_counter += 1\n",
        "\n",
        "        accuracy_sum.append(match_counter / len(y_true_))\n",
        "    \n",
        "    return np.mean(accuracy_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuV1cHXx2PKo",
        "outputId": "0ed6958c-9a39-4f85-c9ce-ac03eb24a2cd"
      },
      "source": [
        "evaluate_accuracy(Y_pred_1, y_test, None) # accuracy without considering the padding label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8220390922548225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pJhxyr42PKp"
      },
      "source": [
        "y_test_1 = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6MxzoI2PKq",
        "outputId": "763659d9-1b92-4be7-92fa-2e6a5e421027"
      },
      "source": [
        "X_train, X_test = x_data[1300:], x_data[:1300]\n",
        "y_train, y_test = y_data[1300:], y_data[:1300]\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[max_sequence_len, 300], dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_sequence_len, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "82/82 [==============================] - 41s 504ms/step - loss: 1.2014 - accuracy: 0.8702\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 43s 526ms/step - loss: 0.3758 - accuracy: 0.8930\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 48s 581ms/step - loss: 0.3367 - accuracy: 0.9027\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 44s 542ms/step - loss: 0.2910 - accuracy: 0.9199\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 41s 500ms/step - loss: 0.2310 - accuracy: 0.9339\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 43s 528ms/step - loss: 0.1801 - accuracy: 0.9471\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 44s 535ms/step - loss: 0.1411 - accuracy: 0.9616\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 44s 537ms/step - loss: 0.1138 - accuracy: 0.9684\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 45s 548ms/step - loss: 0.0974 - accuracy: 0.9724\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 51s 616ms/step - loss: 0.0875 - accuracy: 0.9746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS-M4L2U2PKp"
      },
      "source": [
        "## 2nd "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rDuyUMT2PKq",
        "outputId": "97c759ad-9766-4af3-e319-3b247fd9d390"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 3s 70ms/step - loss: 0.0762 - accuracy: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07621990889310837, 0.9774935245513916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcWC3NI32PKq",
        "outputId": "836ffc70-696b-406c-9fbf-97267fa51d73"
      },
      "source": [
        "Y_pred_2 = model.predict_classes(X_test)\n",
        "Y_pred_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  9, 19, ..., 37, 37, 37],\n",
              "       [ 9,  9,  5, ..., 37, 37, 37],\n",
              "       [ 9,  9, 19, ..., 37, 37, 37],\n",
              "       ...,\n",
              "       [36, 21, 14, ..., 37, 37, 37],\n",
              "       [36,  9,  2, ..., 37, 37, 37],\n",
              "       [ 9,  9,  5, ..., 37, 37, 37]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVKpTNfw2PKr",
        "outputId": "d068fc2e-b317-4fd7-b433-b3d976f9d112"
      },
      "source": [
        "Y_pred_2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1300, 178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saMnx1EX2PKr",
        "outputId": "989abb27-6370-4593-9dd6-bb341d3546f4"
      },
      "source": [
        "evaluate_accuracy(Y_pred_2, y_test, None) # accuracy without considering the padding label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8124230519056513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbVP_05-2PKr"
      },
      "source": [
        "y_test_2 = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7w6VP0w2PKs"
      },
      "source": [
        "y_train = np.array(np.concatenate((y_data[:1300], y_data[2600:]), axis=0))\r\n",
        "X_train = np.array(np.concatenate((x_data[:1300], x_data[2600:]), axis=0))\r\n",
        "X_test = x_data[1300:2600]\r\n",
        "y_test = y_data[1300:2600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pixvywi_2PKr"
      },
      "source": [
        "## 3rd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22JspUpx2PKs",
        "outputId": "a664871b-744b-4fc4-81d3-e710773d3588"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2614, 178, 300), (2614, 178, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNLyZpXg2PKs",
        "outputId": "862bac54-2de4-452f-f7e5-b91acd6fccef"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[max_sequence_len, 300], dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_sequence_len, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "82/82 [==============================] - 40s 493ms/step - loss: 1.2146 - accuracy: 0.8714\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 42s 518ms/step - loss: 0.3680 - accuracy: 0.8960\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 44s 536ms/step - loss: 0.3248 - accuracy: 0.9088\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 41s 499ms/step - loss: 0.2719 - accuracy: 0.9257\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 43s 527ms/step - loss: 0.2026 - accuracy: 0.9412\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 40s 484ms/step - loss: 0.1487 - accuracy: 0.9598\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 42s 513ms/step - loss: 0.1132 - accuracy: 0.9702\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 41s 498ms/step - loss: 0.0930 - accuracy: 0.9744\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 41s 496ms/step - loss: 0.0819 - accuracy: 0.9766\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 40s 483ms/step - loss: 0.0750 - accuracy: 0.9780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSFHezy62PKt",
        "outputId": "cc248b61-684e-4418-8ea1-357f9047229b"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 3s 74ms/step - loss: 0.0688 - accuracy: 0.9792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06878931075334549, 0.9792351126670837]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaTWJOZ_2PKt",
        "outputId": "393de663-15d7-4332-8500-a85b2c9ba068"
      },
      "source": [
        "Y_pred_3 = model.predict_classes(X_test)\n",
        "Y_pred_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 23,  6, ..., 37, 37, 37],\n",
              "       [21, 10, 36, ..., 37, 37, 37],\n",
              "       [21, 10,  5, ..., 37, 37, 37],\n",
              "       ...,\n",
              "       [23,  5, 36, ..., 37, 37, 37],\n",
              "       [21, 14, 10, ..., 37, 37, 37],\n",
              "       [10, 24, 19, ..., 37, 37, 37]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MepcNFn82PKt",
        "outputId": "35970923-4244-484c-bab7-d4d229f55cd1"
      },
      "source": [
        "Y_pred_3.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1300, 178), TensorShape([1300, 178, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phnBr86-2PKt",
        "outputId": "f327869d-0192-429b-d604-f72eddcdf28e"
      },
      "source": [
        "evaluate_accuracy(Y_pred_3, y_test, None) # accuracy without considering the padding label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8386474426992111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH_auOR32PKu"
      },
      "source": [
        "y_test_3 = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUQJnZI62PKu"
      },
      "source": [
        "def class_wise_accuracy(y_pred, y_true):\n",
        "    match_count = [0] * len(unique_labels)\n",
        "    total_count = [0] * len(unique_labels)\n",
        "    \n",
        "    for ctr, _tmp in enumerate(y_pred):\n",
        "    \n",
        "        # find the padding point first\n",
        "        idx = 0\n",
        "        while idx != len(y_true[ctr]) and y_true[ctr][idx] != pad_marker:\n",
        "            idx += 1\n",
        "        \n",
        "        y_pred_ = y_pred[ctr][:idx]\n",
        "        y_true_ = y_true[ctr][:idx]\n",
        "        \n",
        "        for idx, _ in enumerate(y_pred_):\n",
        "            \n",
        "            total_count[y_true_[idx].numpy()[0]] += 1\n",
        "            if y_pred_[idx] == y_true_[idx]:\n",
        "                match_count[y_pred_[idx]] += 1\n",
        "    print(match_count)\n",
        "    print(total_count)\n",
        "    return [match_count[idx] / total_count[idx] if total_count[idx] != 0 else 0 for idx, _ in enumerate(match_count)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI5xUNTS2PKu",
        "outputId": "7abbb7ef-7cd6-409c-f583-7d9801ff5610"
      },
      "source": [
        "class_wise_count = class_wise_accuracy(Y_pred_3, y_test_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 79, 927, 0, 560, 686, 408, 0, 0, 3078, 4081, 818, 0, 0, 1500, 429, 0, 0, 0, 1968, 322, 2412, 400, 1828, 901, 0, 0, 356, 11, 2, 113, 101, 0, 131, 0, 796, 2893, 0]\n",
            "[0, 104, 931, 0, 728, 771, 782, 59, 2, 3220, 4443, 953, 40, 9, 1968, 531, 1, 37, 17, 2106, 324, 2918, 532, 2261, 1087, 34, 47, 817, 74, 56, 225, 128, 8, 156, 30, 868, 3331, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "766khlTX2PKv",
        "outputId": "c88f3357-2d1a-43d6-8a58-c404179ecb37"
      },
      "source": [
        "for idx, score in enumerate(class_wise_count):\n",
        "    print(tokenizer.sequences_to_texts([[idx]])[0], '\\t\\t--->', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \t\t---> 0\n",
            "wp \t\t---> 0.7596153846153846\n",
            "prp \t\t---> 0.9957035445757251\n",
            "sym \t\t---> 0\n",
            "vbn \t\t---> 0.7692307692307693\n",
            "vbz \t\t---> 0.8897535667963683\n",
            "to \t\t---> 0.5217391304347826\n",
            "wrb \t\t---> 0.0\n",
            "uh \t\t---> 0.0\n",
            "nnp \t\t---> 0.9559006211180124\n",
            "nn \t\t---> 0.9185235201440468\n",
            "vb \t\t---> 0.8583420776495279\n",
            "rbr \t\t---> 0.0\n",
            "pdt \t\t---> 0.0\n",
            "jj \t\t---> 0.7621951219512195\n",
            "vbg \t\t---> 0.807909604519774\n",
            "fw \t\t---> 0.0\n",
            "rrb \t\t---> 0.0\n",
            "rbs \t\t---> 0.0\n",
            "nns \t\t---> 0.9344729344729344\n",
            "md \t\t---> 0.9938271604938271\n",
            "dt \t\t---> 0.8265935572309802\n",
            "vbp \t\t---> 0.7518796992481203\n",
            "none \t\t---> 0.8084918177797434\n",
            "rb \t\t---> 0.828886844526219\n",
            "lrb \t\t---> 0.0\n",
            "jjs \t\t---> 0.0\n",
            "cc \t\t---> 0.4357405140758874\n",
            "rp \t\t---> 0.14864864864864866\n",
            "nnps \t\t---> 0.03571428571428571\n",
            "pos \t\t---> 0.5022222222222222\n",
            "jjr \t\t---> 0.7890625\n",
            "ls \t\t---> 0.0\n",
            "wdt \t\t---> 0.8397435897435898\n",
            "ex \t\t---> 0.0\n",
            "vbd \t\t---> 0.9170506912442397\n",
            "in \t\t---> 0.8685079555688983\n",
            "padding \t\t---> 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}